# -*- coding: utf-8 -*-
"""MNIST.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IZszNkn4unAbO4DMd-d69cii66burDYv
"""

from google.colab import drive
drive.mount('/content/drive',force_remount=True)

import os
os.chdir('/content/drive/My Drive/Deep_Learning_hw2/VAE_dataset')

import sys
import torch
import json
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import torch.nn.functional as F
from PIL import Image
import PIL
import torchvision.transforms as transforms
from torch import nn, optim
from torch.utils import data
from torch.utils.data import Dataset, DataLoader
from sklearn.model_selection import train_test_split
from sklearn.utils import shuffle
from  torchvision import utils as vutils
from torchvision.utils import save_image
import torchvision.utils

class Dataset():
    def __init__(self):
        self.image = np.load('./TibetanMNIST.npz')['image']
        # self.loader = transforms.Compose([transforms.Resize(size=(28, 28), interpolation=PIL.Image.BILINEAR),transforms.ToTensor()])
    def __getitem__(self,index):

        image = self.image[index]/255
        threshold = 0.5
        binarized = 1.0 * (image > threshold)
        image_tensor = torch.FloatTensor(binarized)
        return image_tensor,torch.tensor([1])
    def pad_batch(self,batch):
        (image_tensor,label_tensor) = zip(*batch)
        images = torch.stack(image_tensor)
        labels = torch.stack(label_tensor)
        return images,labels
    def __len__(self):
        return len(self.image)


class VAE(nn.Module):
    def __init__(self):
        super(VAE, self).__init__()
        self.encoder = nn.Sequential(
                              nn.Linear(28*28,400),
                              nn.ReLU()
                          )
        self.mean_fc = nn.Sequential(
                              nn.Linear(400,20),    
                              # nn.ReLU()                          
                          )
        self.std_fc = nn.Sequential(
                              nn.Linear(400,20),    
                              # nn.ReLU()                          
                          )
        self.decoder = nn.Sequential(
                              nn.Linear(20,400),
                              nn.ReLU(),
                              nn.Linear(400,28*28)                            
                          )
    def forward(self, pic_tensor): # text = [batch size,sent_length]
        pic_tensor = pic_tensor.reshape(pic_tensor.shape[0],-1)

        encode_vec = self.encoder(pic_tensor)
    
        mu = self.mean_fc(encode_vec)
        log_var = self.std_fc(encode_vec)
        std = torch.exp(log_var/2)
        eps = torch.randn_like(std)
        z = mu + eps * std
        decode_vec = self.decoder(z)
        
        return torch.sigmoid(decode_vec),mu,log_var

def draw_chart(chart_data,outfile_name):
    # -------------- draw loss image --------------
    # -------------- new one figure and set resolution --------------
    plt.figure(figsize=(12.0, 6.0))
    plt.rcParams['savefig.dpi'] = 200
    plt.rcParams['figure.dpi'] = 200
    # -------------- plot data in image --------------
    plt.plot(chart_data['epoch'],chart_data['train_loss'],label='train_loss')
    # -------------- draw underline --------------
    plt.grid(True,axis="y",ls='--')
    # -------------- draw legent --------------
    plt.legend(loc= 'best')
    # -------------- show lable --------------
    plt.xlabel('epoch',fontsize=20)
    # plt.yticks(np.linspace(0,1,11))
    plt.savefig('./'+outfile_name+'_train_loss.jpg')
    # plt.close('all')
    plt.show()

    with open('./'+outfile_name+'.json','w') as file_object:
        json.dump(chart_data,file_object)

def random_sample():
    # sample = torch.empty(64,512).uniform_(0,1)
    sample = torch.randn(64,20)
    # sample = torch.bernoulli(sample)
    return sample

def interpolation(img1,img2):
    image_files = []
    z_1 = img1
    z_2 = img2
    gap = (z_2-z_1)/10
    for i in range(1,10):
        z = z_1 + gap*i
        recon_batch = model.decoder(z)
        save = to_img(recon_batch.cpu().data)
        image_files.append(save)
        save_image(save, './'+str(i)+'.png')

    img_width = 28
    img_height = 28
    img_number = 9

    target = Image.new('L', (img_width * img_number, img_height))
    for i,img_tensor in zip(range(11),image_files):
        target.paste(transforms.ToPILImage()(img_tensor[0]).convert('RGB'), (0+28*i,0))
    target.save('t.png')

def to_img(x):
    x = x.clamp(0, 1)
    x = x.view(x.size(0), 1, 28, 28)
    return x

def show_image(img):
    img = to_img(img)
    npimg = img.numpy()
    plt.imshow(np.transpose(npimg, (1, 2, 0)))

if __name__ == '__main__':

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    batch_size = 128
    learning_rate = 0.001
    model_name = "vae_mnist_model"

    train_set = Dataset()
    train_loader = DataLoader(train_set,batch_size=batch_size,collate_fn=train_set.pad_batch)

    model = VAE()
    model = model.to(device)

    optimizer = optim.Adam(model.parameters(), lr=learning_rate,weight_decay=1e-5)

    chart_data={"train_loss":[],"val_acc":[],"train_acc":[],"epoch":[]}
    criterion = nn.CrossEntropyLoss()
    s = random_sample()

    for epoch in range(100):
        train_loss = 0
        count = 0
        correct = 0
        model.train()
        optimizer.zero_grad()
        for step, (batch) in enumerate(train_loader):

            pic_tensor,_ = [t.to(device) for t in batch]
            decode_vec,mu,log_var = model(pic_tensor)

            reconst_loss = F.binary_cross_entropy(decode_vec, pic_tensor.reshape(pic_tensor.shape[0],-1), size_average=False)
            kl_div = - 0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())


            loss = (reconst_loss + kl_div) / batch_size
            train_loss += loss.item()
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            x_concat = torch.cat([pic_tensor.view(-1, 1, 28, 28), decode_vec.view(-1, 1, 28, 28)], dim=3)
            torch.save(model.state_dict(), './vae.pth')
            if step %1000 == 0:
                print('Epoch: ' , str(epoch) , \
                        '\ttrain_loss: '+str(round(train_loss/(step+1),5)),\
                    )
 
        chart_data['epoch'].append(epoch)
        chart_data['train_loss'].append(train_loss/(step+1))
        draw_chart(chart_data,model_name)
        # save_image(x_concat, './'+str(1)+'.png')
        img = torchvision.utils.make_grid(decode_vec.view(-1, 1, 28, 28))

        # save_image(x_sample, './'+'sample'+str(epoch)+'.png')
        # plt.imshow(img.permute(1, 2, 0))

    with torch.no_grad():
        model.load_state_dict(torch.load('./vae.pth'))
        model.eval()
        decode_s = model.decoder(s)
        x_sample = torch.cat([decode_s.view(-1, 1, 28, 28)], dim=3)

draw_chart(chart_data,model_name)

decode_vec = decode_vec.cpu()
pic_tensor = pic_tensor.cpu()

img2 = torchvision.utils.make_grid(pic_tensor.view(-1, 1, 28, 28))
plt.imshow(img2.permute(1,2,0))
plt.axis('off')
plt.show()


img = torchvision.utils.make_grid(decode_vec.view(-1, 1, 28, 28))
plt.imshow(img.permute(1, 2, 0))
plt.axis('off')
plt.show()

img3 = torchvision.utils.make_grid(x_sample.view(-1, 1, 28, 28))
plt.imshow(img3.permute(1, 2, 0))
plt.axis('off')
plt.show()

interpolation(torch.FloatTensor(20).normal_().reshape(1,-1),torch.FloatTensor(20).normal_().reshape(1,-1))

if __name__ == '__main__':

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    batch_size = 128
    learning_rate = 0.001
    model_name = "vae_mnist_model"

    train_set = Dataset()
    train_loader = DataLoader(train_set,batch_size=batch_size,collate_fn=train_set.pad_batch)

    model = VAE()
    model = model.to(device)

    optimizer = optim.Adam(model.parameters(), lr=learning_rate,weight_decay=1e-5)

    chart_data={"train_loss":[],"val_acc":[],"train_acc":[],"epoch":[]}
    criterion = nn.CrossEntropyLoss()
    s = random_sample()

    for epoch in range(100):
        train_loss = 0
        count = 0
        correct = 0
        model.train()
        optimizer.zero_grad()
        for step, (batch) in enumerate(train_loader):

            pic_tensor,_ = [t.to(device) for t in batch]
            decode_vec,mu,log_var = model(pic_tensor)

            reconst_loss = F.binary_cross_entropy(decode_vec, pic_tensor.reshape(pic_tensor.shape[0],-1), size_average=False)
            kl_div = - 0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())*100


            loss = (reconst_loss + kl_div) / batch_size
            train_loss += loss.item()
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            x_concat = torch.cat([pic_tensor.view(-1, 1, 28, 28), decode_vec.view(-1, 1, 28, 28)], dim=3)
            torch.save(model.state_dict(), './vae.pth')
            if step %1000 == 0:
                print('Epoch: ' , str(epoch) , \
                        '\ttrain_loss: '+str(round(train_loss/(step+1),5)),\
                    )
 
        chart_data['epoch'].append(epoch)
        chart_data['train_loss'].append(train_loss/(step+1))
        save_image(x_concat, './'+str(1)+'.png')


    with torch.no_grad():
        model.eval()
        decode_s = model.decoder(s)
        x_sample = torch.cat([decode_s.view(-1, 1, 28, 28)], dim=3)

draw_chart(chart_data,model_name)

decode_vec = decode_vec.cpu()
pic_tensor = pic_tensor.cpu()

img2 = torchvision.utils.make_grid(pic_tensor.view(-1, 1, 28, 28))
plt.imshow(img2.permute(1,2,0))
plt.axis('off')
plt.show()


img = torchvision.utils.make_grid(decode_vec.view(-1, 1, 28, 28))
plt.imshow(img.permute(1, 2, 0))
plt.axis('off')
plt.show()

img3 = torchvision.utils.make_grid(x_sample.view(-1, 1, 28, 28))
plt.imshow(img3.permute(1, 2, 0))
plt.axis('off')
plt.show()

interpolation(torch.FloatTensor(20).normal_().reshape(1,-1),torch.FloatTensor(20).normal_().reshape(1,-1))

if __name__ == '__main__':

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    batch_size = 128
    learning_rate = 0.001
    model_name = "vae_mnist_model"

    train_set = Dataset()
    train_loader = DataLoader(train_set,batch_size=batch_size,collate_fn=train_set.pad_batch)

    model = VAE()
    model = model.to(device)

    optimizer = optim.Adam(model.parameters(), lr=learning_rate,weight_decay=1e-5)

    chart_data={"train_loss":[],"val_acc":[],"train_acc":[],"epoch":[]}
    criterion = nn.CrossEntropyLoss()
    s = random_sample()

    for epoch in range(100):
        train_loss = 0
        count = 0
        correct = 0
        model.train()
        optimizer.zero_grad()
        for step, (batch) in enumerate(train_loader):

            pic_tensor,_ = [t.to(device) for t in batch]
            decode_vec,mu,log_var = model(pic_tensor)

            reconst_loss = F.binary_cross_entropy(decode_vec, pic_tensor.reshape(pic_tensor.shape[0],-1), size_average=False)
            kl_div = - 0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())*0


            loss = (reconst_loss + kl_div) / batch_size
            train_loss += loss.item()
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            x_concat = torch.cat([pic_tensor.view(-1, 1, 28, 28), decode_vec.view(-1, 1, 28, 28)], dim=3)
            torch.save(model.state_dict(), './vae.pth')
            if step %1000 == 0:
                print('Epoch: ' , str(epoch) , \
                        '\ttrain_loss: '+str(round(train_loss/(step+1),5)),\
                    )
 
        chart_data['epoch'].append(epoch)
        chart_data['train_loss'].append(train_loss/(step+1))
        # save_image(x_concat, './'+str(1)+'.png')

    with torch.no_grad():
        # model.load_state_dict(torch.load('./'+model_name+'.pkl'))
        model.eval()
        decode_s = model.decoder(s)
        x_sample = torch.cat([decode_s.view(-1, 1, 28, 28)], dim=3)

draw_chart(chart_data,model_name)

decode_vec = decode_vec.cpu()
pic_tensor = pic_tensor.cpu()

img2 = torchvision.utils.make_grid(pic_tensor.view(-1, 1, 28, 28))
plt.imshow(img2.permute(1,2,0))
plt.axis('off')
plt.show()


img = torchvision.utils.make_grid(decode_vec.view(-1, 1, 28, 28))
plt.imshow(img.permute(1, 2, 0))
plt.axis('off')
plt.show()

img3 = torchvision.utils.make_grid(x_sample.view(-1, 1, 28, 28))
plt.imshow(img3.permute(1, 2, 0))
plt.axis('off')
plt.show()

interpolation(torch.FloatTensor(20).normal_().reshape(1,-1),torch.FloatTensor(20).normal_().reshape(1,-1))

